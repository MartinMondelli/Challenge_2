{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4890c83-e655-4fc8-9e73-6cd3c1badfcb",
   "metadata": {},
   "source": [
    "# Modèle de Prédiction des Revenus de Films\n",
    "## Clustering + Random Forest avec Optimisation Automatique\n",
    "**Auteurs:** Martín Mondelli et González García Francisco\n",
    "**Date:** 03/11/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2b612",
   "metadata": {},
   "source": [
    "## 1. Importation des Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b6523ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies importées avec succès\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scipy\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "print(\"Librairies importées avec succès\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb0afa7",
   "metadata": {},
   "source": [
    "## 2. Fonctions de Préprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57214094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonctions de préprocessing définies\n"
     ]
    }
   ],
   "source": [
    "def replace_na(df, col):\n",
    "    #Remplace les valeurs nulles et négatives par la médiane de la colonne\n",
    "    median_value = df[col].median()\n",
    "    df[col] = df[col].clip(lower=0)\n",
    "    df[col] = df[col].fillna(0)        \n",
    "    df[col] = df[col].replace(0, median_value)    \n",
    "    return df[col]\n",
    "\n",
    "def compute_outliers(df, col):\n",
    "    #Calcule les limites pour les outliers en utilisant la méthode IQR\n",
    "    Q1, Q3 = df[col].quantile([0.25, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "    return lower, upper\n",
    "\n",
    "def winsorize_df(df, col):\n",
    "    #Applique la winsorisation pour limiter les outliers\n",
    "    lim_inf, lim_sup = compute_outliers(df, col)\n",
    "    series_w = df[col].copy()\n",
    "    series_w = series_w.clip(lower=lim_inf, upper=lim_sup)    \n",
    "    return series_w\n",
    "\n",
    "print(\"Fonctions de préprocessing définies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70823cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction d'ingénierie des caractéristiques définie\n"
     ]
    }
   ],
   "source": [
    "def rescaling_features(df):\n",
    "#Crée des transformations et caractéristiques supplémentaires\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Transformations logarithmiques\n",
    "    df['log_popularity_score'] = np.log(2 + df['popularity_score'])\n",
    "    df['log_budget'] = np.log1p(df['budget'])\n",
    "    \n",
    "    # Transformations polynomiales\n",
    "    df['length_2'] = df['length'] ** 2\n",
    "    df['length_3'] = (2 + df['length']) ** 3\n",
    "    df['popularity_score_2'] = df['popularity_score'] ** 2\n",
    "    df['popularity_score_3'] = (2 + df['popularity_score']) ** 3\n",
    "    df['budget_2'] = df['budget'] ** 2\n",
    "    df['budget_3'] = (2 + df['budget']) ** 3\n",
    "    df['budget_4'] = (df['budget']) ** 4\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Fonction d'ingénierie des caractéristiques définie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d88a8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction de création de variables dummy définie\n"
     ]
    }
   ],
   "source": [
    "def clean_dummies(df):\n",
    "    \n",
    "    #Crée des variables dummy et extrait les caractéristiques de date\n",
    "    \n",
    "    x_dum = df.copy()\n",
    "    \n",
    "    # Extraction de la date\n",
    "    date_split = df[\"date\"].str.split(\"/\", expand=True)\n",
    "    x_dum[\"month\"] = date_split[0].astype(int)\n",
    "    x_dum[\"day\"] = date_split[1].astype(int)\n",
    "    x_dum[\"year\"] = date_split[2].astype(int)\n",
    "    x_dum[\"year\"] = np.where(x_dum[\"year\"] > 27, 1900 + x_dum[\"year\"], 2000 + x_dum[\"year\"])\n",
    "    \n",
    "    # Variables dummy\n",
    "    x_dum[\"sequels\"] = df[\"collection\"].apply(lambda c: 0 if pd.isna(c) else 1)\n",
    "    x_dum[\"marketing\"] = df[\"webpage\"].apply(lambda c: 0 if pd.isna(c) else 1)\n",
    "    x_dum[\"english\"] = df[\"language\"].apply(lambda c: 0 if c==\"en\" else 1)\n",
    "    \n",
    "    # Grandes compagnies (Top 10)\n",
    "    big_companies = [\n",
    "        \"Twentieth Century Fox Film Corporation\", \"Universal Pictures\", \"Warner Bros. Pictures\",\n",
    "        \"Columbia Pictures Corporation\", \"Walt Disney Pictures\", \"Marvel Studios\", \n",
    "        \"Paramount Pictures\", \"Legendary Pictures\", \"New Line Cinema\", \"DreamWorks Animation\"\n",
    "    ]\n",
    "    x_dum[\"big_comp\"] = df[\"company\"].apply(\n",
    "        lambda company: 1 if isinstance(company, str) and any(\n",
    "            big_comp in company for big_comp in big_companies\n",
    "        ) else 0\n",
    "    )\n",
    "    \n",
    "    return x_dum\n",
    "\n",
    "print(\"Fonction de création de variables dummy définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaada0a",
   "metadata": {},
   "source": [
    "## 3. Fonctions de Mise à l'Échelle et Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a34e12f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction de mise à l'échelle définie\n"
     ]
    }
   ],
   "source": [
    "def scale_features(train, test, cols):\n",
    "    #Met à l'échelle les caractéristiques en utilisant StandardScaler\n",
    "    train_scaled = train.copy()\n",
    "    test_scaled = test.copy()\n",
    "\n",
    "    for col in cols:\n",
    "        scaler = StandardScaler()\n",
    "        # Fit en train, transform en ambos\n",
    "        train_scaled[col] = scaler.fit_transform(train[[col]])\n",
    "        test_scaled[col] = scaler.transform(test[[col]])\n",
    "\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "print(\"Fonction de mise à l'échelle définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad9e43",
   "metadata": {},
   "source": [
    "## 4. Fonction Principale du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1cc84153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction de préprocessing définie\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df_train, df_test, target=None):\n",
    "    \n",
    "    #Pipeline complet de préprocessing des données\n",
    "    # 1. Traitement des valeurs manquantes et outliers\n",
    "    for col in [\"budget\", \"length\", \"popularity_score\"]:\n",
    "        df_train[col] = replace_na(df_train, col)\n",
    "        df_train[col] = winsorize_df(df_train, col)\n",
    "        df_test[col] = replace_na(df_test, col)\n",
    "        df_test[col] = winsorize_df(df_test, col)\n",
    "    \n",
    "    # 2. Transformations des caractéristiques\n",
    "    df_train = rescaling_features(df_train)\n",
    "    df_test = rescaling_features(df_test)\n",
    "    \n",
    "    # 3. Création de variables dummy\n",
    "    df_train = clean_dummies(df_train)\n",
    "    df_test = clean_dummies(df_test)\n",
    "    \n",
    "    # 4. Sélection des caractéristiques finales\n",
    "    features = [\"sequels\", \"big_comp\", \"budget\", \"budget_3\", \"length\",\n",
    "                \"log_popularity_score\", \"year\", \"month\"]\n",
    "    \n",
    "    df_train_final = df_train[features]\n",
    "    df_test_final = df_test[features]\n",
    "    \n",
    "    print(f\"Préprocessing terminé. Caractéristiques finales: {len(features)}\")\n",
    "    print(f\"Caractéristiques: {features}\")\n",
    "    \n",
    "    return df_train_final, df_test_final\n",
    "\n",
    "print(\"Fonction de préprocessing définie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99327222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clustered_model(X_train, y_train, X_test):\n",
    "    #Entraîne le modèle complet: Clustering avec 3 clusters + Random Forest par cluster\n",
    "    \n",
    "    print(\"=== DÉBUT DE L'ENTRAÎNEMENT ===\")\n",
    "    \n",
    "    # 1. Préparer les données pour le clustering\n",
    "    num_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "    cols_to_scale = [c for c in num_cols if c not in ['year', 'month']]\n",
    "    \n",
    "    print(f\"Colonnes à mettre à l'échelle pour clustering: {cols_to_scale}\")\n",
    "    \n",
    "    # 2. Mise à l'échelle\n",
    "    X_train_scaled, X_test_scaled = scale_features(X_train, X_test, cols_to_scale)\n",
    "    \n",
    "    # 3. Clustering avec 3 clusters (fixe)\n",
    "    n_clusters = 3\n",
    "    print(f\"Utilisation de {n_clusters} clusters pour le modèle\")\n",
    "    \n",
    "    # 4. Appliquer le clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    train_clusters = kmeans.fit_predict(X_train_scaled[num_cols])\n",
    "    test_clusters = kmeans.predict(X_test_scaled[num_cols])\n",
    "    \n",
    "    # Informations sur les clusters\n",
    "    cluster_sizes = pd.Series(train_clusters).value_counts().sort_index()\n",
    "    print(f\"\\nTailles des clusters dans l'entraînement:\")\n",
    "    for i, size in cluster_sizes.items():\n",
    "        print(f\"  Cluster {i}: {size} observations ({size/len(train_clusters)*100:.1f}%)\")\n",
    "    \n",
    "    # 5. Entraîner Random Forest par cluster\n",
    "    print(\"\\nEntraînement des Random Forest par cluster...\")\n",
    "    cluster_models = {}\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        print(f\"  Entraînement cluster {cluster}...\")\n",
    "        \n",
    "        # Sélectionner les données du cluster\n",
    "        mask = train_clusters == cluster\n",
    "        X_cluster = X_train_scaled.iloc[mask]\n",
    "        y_cluster = np.log1p(y_train.iloc[mask].values.ravel())\n",
    "        \n",
    "        # Entraîner le modèle\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=400,\n",
    "            max_depth=15,\n",
    "            min_samples_leaf=2,\n",
    "            max_features='sqrt',\n",
    "            random_state=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_cluster[num_cols], y_cluster)\n",
    "        cluster_models[cluster] = model\n",
    "    \n",
    "    # 6. Faire les prédictions\n",
    "    y_pred_log = np.zeros(X_test_scaled.shape[0])\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        mask = test_clusters == cluster\n",
    "        if np.any(mask):\n",
    "            X_cluster_test = X_test_scaled.iloc[mask]\n",
    "            y_pred_log[mask] = cluster_models[cluster].predict(X_cluster_test[num_cols])\n",
    "    \n",
    "    # 7. Inverser la transformation logarithmique\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    \n",
    "    # Informations du modèle\n",
    "    cluster_info = {\n",
    "        'n_clusters': n_clusters,\n",
    "        'cluster_sizes': cluster_sizes.to_dict(),\n",
    "        'test_cluster_distribution': pd.Series(test_clusters).value_counts().sort_index().to_dict()\n",
    "    }\n",
    "    return y_pred, cluster_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b9e63",
   "metadata": {},
   "source": [
    "## 5. Fonction pour Formater les Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de9c4210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction de formatage définie\n"
     ]
    }
   ],
   "source": [
    "def format_predictions(y_pred):\n",
    "    #Formate les prédictions comme string séparé par des virgules\n",
    "    str_results = [str(int(np.round(pred, 0))) for pred in y_pred]\n",
    "    return ', '.join(str_results)\n",
    "\n",
    "print(\"Fonction de formatage définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ab54d",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. SECTION D'ÉVALUATION\n",
    "**Cette section sera exécutée par le professeur avec les données privées**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a727087",
   "metadata": {},
   "source": [
    "### Chargement des Données\n",
    "**INSTRUCTIONS POUR LE PROFESSEUR:**\n",
    "- Remplacer les URLs par les chemins des fichiers de données privées\n",
    "- Conserver les noms de variables: `df_train_in`, `y_train`, `df_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e5b9381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>length</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "      <th>collection</th>\n",
       "      <th>company</th>\n",
       "      <th>webpage</th>\n",
       "      <th>poster_file</th>\n",
       "      <th>cast</th>\n",
       "      <th>keywords</th>\n",
       "      <th>crew</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocky V</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>104.0</td>\n",
       "      <td>10/18/90</td>\n",
       "      <td>Drama</td>\n",
       "      <td>A lifetime of taking shots has ended Rocky's c...</td>\n",
       "      <td>Rocky Collection</td>\n",
       "      <td>United Artists</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G6shAlq8wwud6byWm13tLuiR2P5.jpg</td>\n",
       "      <td>Sylvester Stallone,Talia Shire,Burt Young,Sage...</td>\n",
       "      <td>philadelphia,transporter,father son relationsh...</td>\n",
       "      <td>[{'job': 'Director', 'name': 'John G. Avildsen...</td>\n",
       "      <td>14.007329</td>\n",
       "      <td>42000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oculus</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>104.0</td>\n",
       "      <td>9/8/13</td>\n",
       "      <td>Horror</td>\n",
       "      <td>A woman tries to exonerate her brother's murde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intrepid Pictures,Blumhouse Productions,Relati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HcPqD6LzKOPqXkLocfSly49C8ci.jpg</td>\n",
       "      <td>Karen Gillan,Brenton Thwaites,Katee Sackhoff,J...</td>\n",
       "      <td>hallucination,supernatural,mirror,skepticism,g...</td>\n",
       "      <td>[{'job': 'Casting', 'name': 'Anne McCarthy'}, ...</td>\n",
       "      <td>8.698043</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tomorrowland</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5/19/15</td>\n",
       "      <td>Adventure,Family,Mystery,Science Fiction</td>\n",
       "      <td>Bound by a shared destiny, a bright, optimisti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walt Disney Pictures,Babieka,A113</td>\n",
       "      <td>http://movies.disney.com/tomorrowland</td>\n",
       "      <td>MTBS6htgG0g2EUf93yZQNV9zC96.jpg</td>\n",
       "      <td>Britt Robertson,George Clooney,Raffey Cassidy,...</td>\n",
       "      <td>inventor,apocalypse,destiny,imax,dreamer,futur...</td>\n",
       "      <td>[{'job': 'Editor', 'name': 'Craig Wood'}, {'jo...</td>\n",
       "      <td>22.296076</td>\n",
       "      <td>190000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Things Are Tough All Over</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>90.0</td>\n",
       "      <td>8/4/82</td>\n",
       "      <td>Action,Comedy</td>\n",
       "      <td>Cheech and Chong are hired to drive a limo fro...</td>\n",
       "      <td>Cheech &amp; Chong Collection</td>\n",
       "      <td>C &amp; C Brown Production</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vxdj0agTm8reLtxXuzQVkYYx7oA.jpg</td>\n",
       "      <td>Cheech Marin,Tommy Chong,Toni Attell,Mike Baca...</td>\n",
       "      <td>pornography,chicago,money laundering,gas stati...</td>\n",
       "      <td>[{'job': 'Writer', 'name': 'Cheech Marin'}, {'...</td>\n",
       "      <td>9.442756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to Be Single</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1/21/16</td>\n",
       "      <td>Comedy,Romance</td>\n",
       "      <td>New York City is full of lonely hearts seeking...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Line Cinema,Flower Films,Metro-Goldwyn-May...</td>\n",
       "      <td>http://howtobesinglemovie.com/</td>\n",
       "      <td>O8UMYar5eX8iYY5c8qTKO4rFhAj.jpg</td>\n",
       "      <td>Dakota Johnson,Rebel Wilson,Alison Brie,Nichol...</td>\n",
       "      <td>new york,based on novel,one-night stand,single</td>\n",
       "      <td>[{'job': 'Casting', 'name': 'Avy Kaufman'}, {'...</td>\n",
       "      <td>8.898988</td>\n",
       "      <td>38000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title language country  length      date  \\\n",
       "0                    Rocky V       en      US   104.0  10/18/90   \n",
       "1                     Oculus       en      US   104.0    9/8/13   \n",
       "2               Tomorrowland       en      US   130.0   5/19/15   \n",
       "3  Things Are Tough All Over       en      US    90.0    8/4/82   \n",
       "4           How to Be Single       en      US   110.0   1/21/16   \n",
       "\n",
       "                                      genre  \\\n",
       "0                                     Drama   \n",
       "1                                    Horror   \n",
       "2  Adventure,Family,Mystery,Science Fiction   \n",
       "3                             Action,Comedy   \n",
       "4                            Comedy,Romance   \n",
       "\n",
       "                                             summary  \\\n",
       "0  A lifetime of taking shots has ended Rocky's c...   \n",
       "1  A woman tries to exonerate her brother's murde...   \n",
       "2  Bound by a shared destiny, a bright, optimisti...   \n",
       "3  Cheech and Chong are hired to drive a limo fro...   \n",
       "4  New York City is full of lonely hearts seeking...   \n",
       "\n",
       "                  collection  \\\n",
       "0           Rocky Collection   \n",
       "1                        NaN   \n",
       "2                        NaN   \n",
       "3  Cheech & Chong Collection   \n",
       "4                        NaN   \n",
       "\n",
       "                                             company  \\\n",
       "0                                     United Artists   \n",
       "1  Intrepid Pictures,Blumhouse Productions,Relati...   \n",
       "2                  Walt Disney Pictures,Babieka,A113   \n",
       "3                             C & C Brown Production   \n",
       "4  New Line Cinema,Flower Films,Metro-Goldwyn-May...   \n",
       "\n",
       "                                 webpage                      poster_file  \\\n",
       "0                                    NaN  G6shAlq8wwud6byWm13tLuiR2P5.jpg   \n",
       "1                                    NaN  HcPqD6LzKOPqXkLocfSly49C8ci.jpg   \n",
       "2  http://movies.disney.com/tomorrowland  MTBS6htgG0g2EUf93yZQNV9zC96.jpg   \n",
       "3                                    NaN  vxdj0agTm8reLtxXuzQVkYYx7oA.jpg   \n",
       "4         http://howtobesinglemovie.com/  O8UMYar5eX8iYY5c8qTKO4rFhAj.jpg   \n",
       "\n",
       "                                                cast  \\\n",
       "0  Sylvester Stallone,Talia Shire,Burt Young,Sage...   \n",
       "1  Karen Gillan,Brenton Thwaites,Katee Sackhoff,J...   \n",
       "2  Britt Robertson,George Clooney,Raffey Cassidy,...   \n",
       "3  Cheech Marin,Tommy Chong,Toni Attell,Mike Baca...   \n",
       "4  Dakota Johnson,Rebel Wilson,Alison Brie,Nichol...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  philadelphia,transporter,father son relationsh...   \n",
       "1  hallucination,supernatural,mirror,skepticism,g...   \n",
       "2  inventor,apocalypse,destiny,imax,dreamer,futur...   \n",
       "3  pornography,chicago,money laundering,gas stati...   \n",
       "4     new york,based on novel,one-night stand,single   \n",
       "\n",
       "                                                crew  popularity_score  \\\n",
       "0  [{'job': 'Director', 'name': 'John G. Avildsen...         14.007329   \n",
       "1  [{'job': 'Casting', 'name': 'Anne McCarthy'}, ...          8.698043   \n",
       "2  [{'job': 'Editor', 'name': 'Craig Wood'}, {'jo...         22.296076   \n",
       "3  [{'job': 'Writer', 'name': 'Cheech Marin'}, {'...          9.442756   \n",
       "4  [{'job': 'Casting', 'name': 'Avy Kaufman'}, {'...          8.898988   \n",
       "\n",
       "      budget  \n",
       "0   42000000  \n",
       "1    5000000  \n",
       "2  190000000  \n",
       "3          0  \n",
       "4   38000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DONNÉES D'ENTRAÎNEMENT ET DE TEST\n",
    "# TODO: Remplacer ces URLs par ses fichiers privés\n",
    "\n",
    "df_train_in = pd.read_csv(\"https://edouardpauwels.fr/MLM2DSSS/challenge_train_features.csv\", index_col=0)\n",
    "y_train = pd.read_csv(\"https://edouardpauwels.fr/MLM2DSSS/challenge_train_revenue.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"https://edouardpauwels.fr/MLM2DSSS/challenge_test_features.csv\", index_col=0)\n",
    "display(df_train_in.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c302a3e",
   "metadata": {},
   "source": [
    "### Préprocessing des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cbe521bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préprocessing terminé. Caractéristiques finales: 8\n",
      "Caractéristiques: ['sequels', 'big_comp', 'budget', 'budget_3', 'length', 'log_popularity_score', 'year', 'month']\n"
     ]
    }
   ],
   "source": [
    "# Appliquer le préprocessing complet\n",
    "X_train_processed, X_test_processed = preprocess_data(df_train_in.copy(), df_test.copy(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c8e26",
   "metadata": {},
   "source": [
    "### Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1439b249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DÉBUT DE L'ENTRAÎNEMENT ===\n",
      "Colonnes à mettre à l'échelle pour clustering: ['sequels', 'big_comp', 'budget', 'budget_3', 'length', 'log_popularity_score']\n",
      "Utilisation de 3 clusters pour le modèle\n",
      "\n",
      "Tailles des clusters dans l'entraînement:\n",
      "  Cluster 0: 682 observations (34.1%)\n",
      "  Cluster 1: 118 observations (5.9%)\n",
      "  Cluster 2: 1200 observations (60.0%)\n",
      "\n",
      "Entraînement des Random Forest par cluster...\n",
      "  Entraînement cluster 0...\n",
      "  Entraînement cluster 1...\n",
      "  Entraînement cluster 2...\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle avec 3 clusters\n",
    "predictions, model_info = train_clustered_model(\n",
    "    X_train_processed, \n",
    "    y_train, \n",
    "    X_test_processed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc1abc",
   "metadata": {},
   "source": [
    "### Résultats Finaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0933b7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRÉDICTIONS FINALES ===\n",
      "96704075, 6193138, 2656040, 8882629, 1550422, 108381944, 18546605, 38221536, 2515100, 58930139, 57160921, 976972, 40267465, 8108776, 1158704, 8777461, 2459817, 3058598, 3020207, 7257316, 15536941, 57440753, 13574541, 102212, 11218523, 637465, 2132448, 4783198, 442717, 63205, 62556193, 26407233, 5389237, 28549499, 2398986, 114143952, 5984074, 2672016, 20816191, 799193, 10673539, 26071645, 32220631, 175478514, 44305963, 6548915, 3036525, 1088616, 14041889, 28601306, 165303532, 28448912, 332034443, 7363610, 5808092, 19210413, 759891, 58325931, 196470846, 6023609, 5063543, 4211587, 8556088, 53530374, 12180098, 1120661, 1388701, 2270729, 55857017, 228539622, 17317251, 2599778, 54285, 65369, 4318357, 347299, 62688534, 1606372, 14040270, 17472618, 1365191, 10822786, 54863721, 878876, 4221861, 17718852, 23503794, 42289609, 1891685, 53383887, 58311511, 73262614, 5249666, 7847649, 23981600, 2470633, 1514734, 702575, 21798586, 30511616, 256561376, 4120993, 20441310, 1075874, 1524258, 42011436, 117032, 3568637, 2322730, 10720120, 124620491, 7006710, 1950891, 573597, 82286, 488778, 111114669, 57030963, 3082499, 18420604, 200532251, 10583104, 1717690, 482068, 66536299, 48271419, 26449709, 16809347, 406454, 11800946, 34606035, 1484198, 96000318, 3992, 16729739, 3023979, 1473583, 3128896, 377413, 2817183, 195318955, 28751377, 7310045, 129625345, 222549438, 4390358, 6975431, 4156629, 5903070, 4409400, 120991231, 44122, 29673985, 18214674, 15013085, 26207622, 71728070, 1454848, 9495276, 1335418, 87886731, 4421278, 20966979, 2654495, 657192, 12064032, 2204540, 45257292, 339473142, 41189812, 2157268, 1252877, 27883558, 141445671, 4234472, 525968156, 26787461, 5431350, 458222, 26111569, 2782615, 38758239, 5172665, 20834843, 19307252, 784058, 1159176, 337398576, 18306390, 3173399, 358421, 4187149, 126672, 55197678, 15817868, 11400196, 23111495, 688219, 211467458, 7108461, 13066334, 147895092, 172329393, 16393162, 4208017, 188872, 5413260, 31783253, 1466508, 174565715, 27002639, 9348864, 23601063, 8425131, 10877361, 68487102, 2456376, 12833881, 14478814, 2255490, 2795027, 2415445, 186782217, 25097226, 56573797, 50671535, 39474582, 58618947, 4435384, 589340, 149346, 374204, 62745, 2033763, 158153797, 22974268, 1115208, 5022728, 2730234, 11343997, 104096, 1281578, 88413165, 2002865, 53752946, 18354628, 4550958, 8322756, 33812216, 39385787, 124238250, 4901243, 1666413, 2944534, 1334866, 40051952, 91459857, 94027, 18975718, 458209, 5957472, 2688161, 44868286, 63970299, 27237890, 2434640, 148110823, 74684609, 9205430, 43498330, 16670828, 20658564, 76949282, 147205570, 83622, 49702164, 47945507, 13915085, 20476002, 5940596, 51035036, 831412, 13972163, 24375150, 127973, 3783180, 8941987, 256224627, 1312125, 40392490, 17490643, 3164542, 2086623, 78305301, 42391109, 56497613, 57744580, 50421052, 20582032, 145309941, 43647942, 242336, 742994, 27557813, 8435483, 704860, 27918100, 52151, 1579242, 5006475, 26196532, 42925853, 15025557, 108962380, 24747602, 35538, 3815505, 8553374, 1864996, 46288155, 46806823, 47699957, 5058740, 156709698, 1819354, 85266, 185017262, 122147246, 820062, 3051123, 456099, 5901922, 29148062, 4286795, 1030207, 2937067, 20300587, 161648980, 7403849, 458349, 33984269, 3019504, 2133575, 47078532, 4666716, 35769085, 27103888, 7619588, 776270, 5598922, 6269997, 69592805, 1075304, 161040192, 5703821, 63827974, 390215, 72269371, 2620450, 41551036, 87361485, 330943, 3619055, 10235519, 329183, 1230380, 75694211, 5514654, 461455, 5591090, 20060623, 27897033, 23383811, 76015, 67229953, 236510792, 50283016, 9838046, 7950575, 27817025, 3128726, 286942, 33278310, 431358, 127393325, 219265055, 30293883, 888515, 44894595, 70100243, 27790982, 45166572, 17184881, 8152895, 560038, 4664705, 494116, 29931717, 89361, 2080857, 26582631, 22471210, 107092599, 711828, 100022444, 133841573, 2787669, 587448, 209329, 20254938, 105906084, 22061075, 3550588, 9708181, 7104948, 638030458, 1239617, 433191, 12801181, 2883271, 39676824, 1073383, 4380127, 31089240, 62909834, 59531184, 106933, 65576, 60905599, 6280389, 1868799, 1510629, 802713, 128938752, 402236757, 10066895, 10117876, 25129183, 153003752, 375217, 40454741, 74883, 99814784, 296649265, 8135773, 11608609, 582019, 63187, 10796492, 57339821, 241959013, 22076539, 33068969, 7700210, 45638768, 245976, 554466534, 82382598, 39635409, 765146, 146302939, 20829165, 2144204, 147581408, 7249103, 54028152, 591474, 21870287, 52863827, 22176781, 43848639, 110566, 394743, 1863799, 378162, 44604231, 3589896, 43444324, 59905335, 5326871, 1388265, 166575511, 89650954, 6406433, 85370350, 24231396, 56474, 4283831, 28393854, 722788, 95434909, 200549330, 10799184, 138703556, 13725219, 3116006, 6008425, 4802841, 18462653, 3450682\n",
      "\n",
      "=== RÉSUMÉ ===\n",
      "Total des prédictions: 500\n",
      "Modèle utilisé: Clustering (3 clusters) + Random Forest\n",
      "Informations du modèle final:\n",
      "  - Nombre de clusters: 3\n",
      "  - Distribution des clusters dans l'entraînement: {0: 682, 1: 118, 2: 1200}\n",
      "  - Distribution des clusters dans le test: {0: 189, 1: 28, 2: 283}\n"
     ]
    }
   ],
   "source": [
    "# Formater les prédictions pour la livraison\n",
    "result_string = format_predictions(predictions)\n",
    "\n",
    "print(\"=== PRÉDICTIONS FINALES ===\")\n",
    "print(result_string)\n",
    "print(f\"\\n=== RÉSUMÉ ===\")\n",
    "print(f\"Total des prédictions: {len(predictions)}\")\n",
    "print(f\"Modèle utilisé: Clustering ({model_info['n_clusters']} clusters) + Random Forest\")\n",
    "print(f\"Informations du modèle final:\")\n",
    "print(f\"  - Nombre de clusters: {model_info['n_clusters']}\")\n",
    "print(f\"  - Distribution des clusters dans l'entraînement: {model_info['cluster_sizes']}\")\n",
    "print(f\"  - Distribution des clusters dans le test: {model_info['test_cluster_distribution']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
